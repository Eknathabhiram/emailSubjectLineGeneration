{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ryanzhumich/AESLC.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxO6PDY-FN9_","outputId":"82feccc7-97a9-450e-a18b-e9bbc1362cbe","execution":{"iopub.status.busy":"2023-11-26T04:33:07.120000Z","iopub.execute_input":"2023-11-26T04:33:07.120270Z","iopub.status.idle":"2023-11-26T04:33:10.173073Z","shell.execute_reply.started":"2023-11-26T04:33:07.120243Z","shell.execute_reply":"2023-11-26T04:33:10.171815Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'AESLC'...\nremote: Enumerating objects: 17469, done.\u001b[K\nremote: Counting objects: 100% (8/8), done.\u001b[K\nremote: Compressing objects: 100% (8/8), done.\u001b[K\nremote: Total 17469 (delta 1), reused 0 (delta 0), pack-reused 17461\u001b[K\nReceiving objects: 100% (17469/17469), 7.36 MiB | 14.95 MiB/s, done.\nResolving deltas: 100% (48/48), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip show sacrebleu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UB7IXLOxnYd_","outputId":"6e29f0bc-6821-4aef-fa90-ac07293dd8d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[33mWARNING: Package(s) not found: sacrebleu\u001b[0m\u001b[33m\n\n\u001b[0m"}]},{"cell_type":"code","source":"!pip install evaluate sacrebleu\n!pip install evaluate rouge_score","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWFBT2yUFZNp","outputId":"31034c52-e37b-48c5-9a91-7ea07648d9fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting evaluate\n\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hCollecting sacrebleu\n\n  Downloading sacrebleu-2.3.2-py3-none-any.whl (119 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n\n  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n\nCollecting dill (from evaluate)\n\n  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n\nCollecting multiprocess (from evaluate)\n\n  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n\nCollecting responses<0.19 (from evaluate)\n\n  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n\nCollecting portalocker (from sacrebleu)\n\n  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n\nCollecting colorama (from sacrebleu)\n\n  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n\nRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n\nCollecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n\nInstalling collected packages: pyarrow-hotfix, portalocker, dill, colorama, sacrebleu, responses, multiprocess, datasets, evaluate\n\nSuccessfully installed colorama-0.4.6 datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 portalocker-2.8.2 pyarrow-hotfix-0.6 responses-0.18.0 sacrebleu-2.3.2\n\nRequirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n\nCollecting rouge_score\n\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.15.0)\n\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n\nRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.6.3)\n\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n\nBuilding wheels for collected packages: rouge_score\n\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=7916fe6f362348b4db4de7cf63511011d197292367f7c913899bbd696a5ce69d\n\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n\nSuccessfully built rouge_score\n\nInstalling collected packages: rouge_score\n\nSuccessfully installed rouge_score-0.1.2\n"}]},{"cell_type":"code","source":"!pip uninstall transformers accelerate\n!pip install transformers[torch]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alLHa_f-FfA6","outputId":"2fc9db15-42a6-47ab-d108-55adcac63fff","execution":{"iopub.status.busy":"2023-11-26T04:33:10.176218Z","iopub.execute_input":"2023-11-26T04:33:10.176695Z","iopub.status.idle":"2023-11-26T04:34:34.941519Z","shell.execute_reply.started":"2023-11-26T04:33:10.176652Z","shell.execute_reply":"2023-11-26T04:34:34.940057Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.35.0\nUninstalling transformers-4.35.0:\n  Would remove:\n    /opt/conda/bin/transformers-cli\n    /opt/conda/lib/python3.10/site-packages/transformers-4.35.0.dist-info/*\n    /opt/conda/lib/python3.10/site-packages/transformers/*\nProceed (Y/n)? ^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.24.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nfrom nltk.translate.bleu_score import corpus_bleu\nimport numpy as np\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import EvalPrediction\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"id":"Oo03oArKFhcu","execution":{"iopub.status.busy":"2023-11-26T04:34:53.550263Z","iopub.execute_input":"2023-11-26T04:34:53.550752Z","iopub.status.idle":"2023-11-26T04:34:53.573121Z","shell.execute_reply.started":"2023-11-26T04:34:53.550707Z","shell.execute_reply":"2023-11-26T04:34:53.572211Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ndef prep_training_data(output_file,input_path):\n\n  count=0\n  with open(output_file, 'w', encoding='utf-8') as train_sequence:\n    for file_name in os.listdir(input_path):\n      # if file_name.endswith(\".txt\"):\n        file_path = os.path.join(input_path,file_name)\n        with open(file_path,'r',encoding='utf-8') as reader:\n          email,subject=reader.read().split(\"@subject\")\n          email = ' '.join(email.replace('\\n',' ').split()).strip()\n          subject = ' '.join(subject.replace('\\n',' ').split()).strip()\n          sequence = '<email> ' + email + '   <subject> ' + subject\n          train_sequence.write(sequence + '\\n')\n  return\n","metadata":{"id":"K_s7nxD8FkDw","execution":{"iopub.status.busy":"2023-11-26T04:34:53.574157Z","iopub.execute_input":"2023-11-26T04:34:53.574508Z","iopub.status.idle":"2023-11-26T04:34:53.584066Z","shell.execute_reply.started":"2023-11-26T04:34:53.574480Z","shell.execute_reply":"2023-11-26T04:34:53.583153Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\ndef prep_validation_data(output_file,input_path):\n    count=0\n    with open(output_file, 'w', encoding='utf-8') as validation_sequence:\n      for file_name in os.listdir(input_path):\n        # if file_name.endswith(\".txt\"):\n          file_path = os.path.join(input_path,file_name)\n          with open(file_path,'r',encoding='utf-8') as reader:\n            email,email_right = reader.read().split('@subject')\n            subject,subject_right  = email_right.split('@ann0')\n            ann0,ann0_right = subject_right.split('@ann1')\n            ann1,ann2 = ann0_right.split('@ann2')\n\n            email = ' '.join(email.replace('\\n',' ').split()).strip()\n            subject = ' '.join(subject.replace('\\n',' ').split()).strip()\n            ann0 = ' '.join(ann0.replace('\\n',' ').split()).strip()\n            ann1 = ' '.join(ann1.replace('\\n',' ').split()).strip()\n            ann2 = ' '.join(ann2.replace('\\n',' ').split()).strip()\n            sequence = '<email> ' + email + '   <subject> ' + subject\n            validation_sequence.write(sequence + '\\n')\n    return","metadata":{"id":"CokvAYkvFzNQ","execution":{"iopub.status.busy":"2023-11-26T04:34:53.585218Z","iopub.execute_input":"2023-11-26T04:34:53.585547Z","iopub.status.idle":"2023-11-26T04:34:53.595037Z","shell.execute_reply.started":"2023-11-26T04:34:53.585522Z","shell.execute_reply":"2023-11-26T04:34:53.594064Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"prep_training_data('/kaggle/working/training_sequence.txt','/kaggle/working/AESLC/enron_subject_line/train')\nprep_validation_data('/kaggle/working/validating_sequence.txt','/kaggle/working//AESLC/enron_subject_line/dev')","metadata":{"id":"N4-dHKs5F2W7","execution":{"iopub.status.busy":"2023-11-26T04:35:52.698978Z","iopub.execute_input":"2023-11-26T04:35:52.699679Z","iopub.status.idle":"2023-11-26T04:35:53.574462Z","shell.execute_reply.started":"2023-11-26T04:35:52.699641Z","shell.execute_reply":"2023-11-26T04:35:53.573585Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"gpt2\"\ntokenizer = GPT2Tokenizer.from_pretrained(checkpoint)  # also try gpt2-medium\nmodel = GPT2LMHeadModel.from_pretrained(checkpoint)\nextra_tokens = [\"<email>\", \"<subject>\"]\ntokenizer.add_tokens(extra_tokens)\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\nmodel.resize_token_embeddings(len(tokenizer))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLXOe7N8F4jR","outputId":"d4b3cbf2-0a76-4a85-e931-c6b114dcc4ea","execution":{"iopub.status.busy":"2023-11-26T04:36:09.734379Z","iopub.execute_input":"2023-11-26T04:36:09.735216Z","iopub.status.idle":"2023-11-26T04:36:16.278651Z","shell.execute_reply.started":"2023-11-26T04:36:09.735183Z","shell.execute_reply":"2023-11-26T04:36:16.277663Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b780690962f47d38af8b838cdae8557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17016b919d4343ac9187e82ee6e2c587"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f992b7ce2f4af68cd12b00e679fc2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ade6bea3863d4153986b8b230defb1d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd711fc472e42f6876d740dfb2e2860"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccefb5cf22d44be8aae3ff6c54de8c0e"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Embedding(50260, 768)"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataset_path,tokenizer):\n        super().__init__()\n\n        email_subject_path = dataset_path\n\n        self.data_list = []\n        self.eos_token_id = tokenizer.eos_token_id\n\n        with open(email_subject_path) as file:\n          for line in file:\n            data_str= line\n            self.data_list.append(data_str)\n\n    def __len__(self):\n        return len(self.data_list)\n\n    def __getitem__(self, item):\n        data = self.data_list[item]\n        encoding = tokenizer(data, return_tensors=\"pt\", truncation=True, padding=True)\n\n        return {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n        }\n","metadata":{"id":"FCggSbprZQ6W","execution":{"iopub.status.busy":"2023-11-26T04:36:31.770606Z","iopub.execute_input":"2023-11-26T04:36:31.771005Z","iopub.status.idle":"2023-11-26T04:36:31.779554Z","shell.execute_reply.started":"2023-11-26T04:36:31.770971Z","shell.execute_reply":"2023-11-26T04:36:31.778532Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# train_dataset = TextDataset(tokenizer=tokenizer, file_path=\"/content/training_sequence.txt\", block_size=128)\n# val_dataset = TextDataset(tokenizer=tokenizer, file_path=\"/content/validating_sequence.txt\", block_size=128)\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\ntrain_dataset = CustomDataset( dataset_path=\"/kaggle/working/training_sequence.txt\",tokenizer=tokenizer)\nval_dataset = CustomDataset(dataset_path=\"/kaggle/working/training_sequence.txt\",tokenizer=tokenizer)","metadata":{"id":"4GlSiniXGCwP","execution":{"iopub.status.busy":"2023-11-26T04:37:21.670208Z","iopub.execute_input":"2023-11-26T04:37:21.670967Z","iopub.status.idle":"2023-11-26T04:37:21.704694Z","shell.execute_reply.started":"2023-11-26T04:37:21.670932Z","shell.execute_reply":"2023-11-26T04:37:21.703664Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"type(train_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ep-pa4zQwdK","outputId":"bcea6943-3359-4bf0-d6e8-a251d24c2a51","execution":{"iopub.status.busy":"2023-11-26T04:37:26.646102Z","iopub.execute_input":"2023-11-26T04:37:26.646818Z","iopub.status.idle":"2023-11-26T04:37:26.652996Z","shell.execute_reply.started":"2023-11-26T04:37:26.646782Z","shell.execute_reply":"2023-11-26T04:37:26.652031Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"__main__.CustomDataset"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"1lDCrCkuRuk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_output_path = \"/content/gpt_model\"\n\ntraining_args = TrainingArguments(\n          output_dir=model_output_path,\n          overwrite_output_dir=True,\n          evaluation_strategy = 'steps',\n          eval_steps = 1000,\n          # save_strategy = 'epoch',\n          per_device_train_batch_size=2,  # Adjust as needed based on your GPU memory\n          per_device_eval_batch_size=2,\n          gradient_accumulation_steps=2,\n          num_train_epochs=4,\n          fp16=True\n      )","metadata":{"id":"iuh9iJhsGDtV","execution":{"iopub.status.busy":"2023-11-26T05:02:58.168915Z","iopub.execute_input":"2023-11-26T05:02:58.169759Z","iopub.status.idle":"2023-11-26T05:02:58.179677Z","shell.execute_reply.started":"2023-11-26T05:02:58.169720Z","shell.execute_reply":"2023-11-26T05:02:58.178591Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from transformers.integrations import WandbCallback\n\n# Temporarily disable WandbCallback\nWandbCallback.wandb = None\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T04:49:53.313498Z","iopub.execute_input":"2023-11-26T04:49:53.313866Z","iopub.status.idle":"2023-11-26T04:49:53.320434Z","shell.execute_reply.started":"2023-11-26T04:49:53.313835Z","shell.execute_reply":"2023-11-26T04:49:53.319188Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n          model=model,\n          args=training_args,\n          data_collator=data_collator,\n          train_dataset=train_dataset,\n          eval_dataset=val_dataset,\n          # preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n          # compute_metrics=compute_metrics\n  )\ntrainer.train()\ntrainer.save_model()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"3rzQ3BXrGi_x","outputId":"1a6f2575-1fda-41ca-a90c-7fb47d9bb505","execution":{"iopub.status.busy":"2023-11-26T05:03:01.353147Z","iopub.execute_input":"2023-11-26T05:03:01.354086Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5083' max='7216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5083/7216 1:45:44 < 44:23, 0.80 it/s, Epoch 2.82/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>3.458800</td>\n      <td>3.218062</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.277000</td>\n      <td>3.046602</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.160000</td>\n      <td>2.941843</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.030200</td>\n      <td>2.864614</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.998200</td>\n      <td>2.813260</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/content/gpt_model/checkpoint-7000', 'zip', '/content')","metadata":{"id":"GYnk5eQK7QjE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n# Load the fine-tuned GPT-2 model and modified tokenizer\nmodel_path = \"/content/gpt_model/checkpoint-4000\"\n# tokenizer = GPT2Tokenizer.from_pretrained(model_path)\nmodel = GPT2LMHeadModel.from_pretrained(model_path)\n\n# Set the device to GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHTNPVOq55Rw","outputId":"12223839-cf7b-4f48-c5c4-409cb2467fcb"},"execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50260, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"# Use the model for text generation\nprompt = \"\"\"UBS have organized an important meeting  will be held tomorrow for all employees who :   1) have accepted offers or  2) intend to accept offers ( to the best of their knowledge) but who have issues that are being resolved  All employees in these categories should attend  Buses will be provided for those who do not have their own transport and will pick up from the south side of the north building - please assemble in the Java plaza area from 8.30am  to 9.30am ( last bus leaves  @ 9.30 am )  The meeting will last until approximately 1pm  and will be presented by senior managers from UBS on the firm and it's strategy.\nThere will be breakfast available at the Hotel from 9am to 10am and there will be sandwiches afterwards.\nIf traveling independently please make sure you leave sufficient time to park (it will be very busy) and get to the Grand ballroom  Employees need to bring their id's or drivers license with them to gain access to the meeting  I'm sorry for the short notice on this - please call out to anyone who should be attending who will not get this message in time    Tammie Schoppe  on behalf of UBS HR\"\"\"\ninput_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\nattention_mask = torch.ones_like(input_ids)\npad_token_id = tokenizer.eos_token_id\noutput_ids = model.generate(input_ids, max_length=1024, num_return_sequences=1,attention_mask=attention_mask,\n        pad_token_id=pad_token_id)\n\n# Decode and print the generated text\ngenerated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\nprint(generated_text)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBLjFp1R7Wx-","outputId":"11a05c94-a8d3-4e60-87b9-f5b56725e9e8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"UBS have organized an important meeting  will be held tomorrow for all employees who :   1) have accepted offers or  2) intend to accept offers ( to the best of their knowledge) but who have issues that are being resolved  All employees in these categories should attend  Buses will be provided for those who do not have their own transport and will pick up from the south side of the north building - please assemble in the Java plaza area from 8.30am  to 9.30am ( last bus leaves  @ 9.30 am )  The meeting will last until approximately 1pm  and will be presented by senior managers from UBS on the firm and it's strategy.\n\nThere will be breakfast available at the Hotel from 9am to 10am and there will be sandwiches afterwards.\n\nIf traveling independently please make sure you leave sufficient time to park (it will be very busy) and get to the Grand ballroom  Employees need to bring their id's or drivers license with them to gain access to the meeting  I'm sorry for the short notice on this - please call out to anyone who should be attending who will not get this message in time    Tammie Schoppe  on behalf of UBS HR    <subject>  Meeting tomorrow @ 9am\n\n<eos>\n\n<eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"}]}]}